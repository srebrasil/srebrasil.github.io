---
layout: post 
title:  "Desafios n√£o √≥bvios para adotar Canary Releases"
date:   2022-07-31 08:00:00 -0300 --->
published: true
tag: "Edi√ß√£o #21 - 01.09.2022"
headline: "Desafios n√£o √≥bvios para adotar Canary Releases"
highlight_title: "When to kill the canary"
highlight_url: "https://blixhavn.dev/when-to-kill-the-canary/"
highlight_autor: "√òystein Blixhavn"
image: /images/canary_release_post.png
comentado_por: "Ricardo Coelho de Sousa"
comentado_por_linkedin: "http://linkedin.com/in/rcsousa1/"
---
Modernizar ou desenvolver aplica√ß√µes modernas, distribu√≠das, baseadas em microservi√ßos, e sobre um stack de tecnologia atual como kubernetes, tem muitos desafios. Entretanto, tamb√©m cria muitas oportunidades para inovar e otimizar a forma como desenvolvemos e implementamos software em produ√ß√£o. 

Como quase todos visualizam que, na medida em que evoluam em suas jornadas, conseguir√£o implementar c√≥digo em produ√ß√£o v√°rias vezes ao dia com qualidade, t√©cnicas como canary release tornaram-se a resposta padr√£o para que times conseguissem automatizar a implementa√ß√£o em produ√ß√£o sem necessidade dos famosos e odiados CABs (Change Approval Boards). Ademais, se houvesse problema com o release, a t√©cnica de canary release seria capaz de prevenir a propaga√ß√£o do problema e interromper o roll-out, permitindo que a√ß√µes de roll-back ou de corre√ß√£o fossem executadas para preservar a experi√™ncia dos usu√°rios / clientes.

Parece √≥timo e na verdade √© bem coerente. No entanto, na medida em que as empresas avan√ßam, o que √© foco do artigo em destaque, aprendem que n√£o √© t√£o f√°cil implementar essa t√©cnica e que a decis√£o de quando "matar o can√°rio" na verdade depende de um grande conjunto de vari√°veis din√¢micas e que tem efeitos diversos umas nas outras (sistemas complexos). A determina√ß√£o de SLIs e a monitora√ß√£o dos golden signals, elementos da cartilha SRE, certamente ajudam e s√£o importantes, mas pouco se sabe sobre como a varia√ß√£o desses indicadores podem gerar alertas objetivos e que possam ser utilizados como instrumento para tomada de decis√£o para interromper ou deixar um roll-out prosseguir de forma automatizada.

O artigo destaca alguns exemplos importantes. Imagine que sua estrat√©gia de monitora√ß√£o inclua a observ√¢ncia do percentil 90 da taxa de erros para chamadas http em uma determinada API (HTTP 500):

- Quanto essa tava deve variar no percentil 90 para que se decida por puxar o plug e interromper o roll-out? 
- E se o problema que sirva como gatilho para o aumento na taxa de error somente ocorra durante hor√°rios de pico muito espec√≠ficos em que seus usu√°rios utilizem uma fun√ß√£o espec√≠fica que acessa essa API? 
- Mais complexo ainda: E se voc√™ tiver lan√ßado uma sequ√™ncia de releases com fun√ß√£o desativadas (dark deploy) e o impacto somente seja revelado na medida em que a curva de ado√ß√£o das novas funcionalidades ocorreram. 

Identificar esses problemas pode demorar semanas. Na verdade, √© poss√≠vel inclusive que s√≥ sejam identificados depois de alguns outros releases tenham sido lan√ßados. Esse tema √© muito complexo, e para o qual n√£o existem resposta simples. O pr√≥prio autor inclusive lista alguns casos mas admite o pr√≥prio desconhecimento sobre como resolver essas quest√µes. 

Eu tenho a sensa√ß√£o que ser√° necess√°rio ainda algum tempo para que possamos encontrar um equil√≠brio adequado para adotar continuous deploy para sistemas cr√≠ticos e que certamente canary release √© uma alternativa promissora. No entanto, ela deve ser implementada em conjunto com outras t√©cnicas como pair programing, chaos engineering, etc. 

Precisamos urgentemente encontrar formas de aprender sobre o comportamento dos nossos sistemas mais r√°pido do que nossos usu√°rios. Talvez assim seja poss√≠vel termos sistemas confi√°veis üòÑ 

Confiram o artigo na integra!